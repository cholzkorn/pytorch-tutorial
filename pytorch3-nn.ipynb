{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# Imports\n",
    "# MNIST not in Tensor format yet -> transforms.ToTensor\n",
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()])) \n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()])) \n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# build neural network\n",
    "class Net(nn.Module): # inherit from nn.Module\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__() # run initialization for nn.Module\n",
    "        self.fc1 = nn.Linear(28*28, 64) # first fully connected layer, 64 arbitrary\n",
    "        self.fc2 = nn.Linear(64, 64) # has to take the output from first layer\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10) # 10 classes: 0,1,2,3,4,5,6,7,8,9\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # feed-forward neural network, x passes through all layers\n",
    "        x = F.relu(self.fc1(x)) # activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x) # output layer\n",
    "        return F.log_softmax(x, dim=1) # add softmax activation to output\n",
    "        \n",
    "# STATE MODEL        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass data through Neural Network\n",
    "X = torch.rand((28,28))\n",
    "X = X.view(-1, 28*28) # -1 means \"any size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1875, -2.2766, -2.3346, -2.3528, -2.4070, -2.3551, -2.4829, -2.2057,\n",
       "         -2.2423, -2.2223]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0247, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0145, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) # learning rate\n",
    "\n",
    "EPOCHS = 3 # number of whole passes through entire dataset\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # data is a batch of features and labels\n",
    "        X, y = data\n",
    "        net.zero_grad() # we want to start at 0 with these gradients\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y) # our dataset has scalar value output, for OH encoded choose mean squared error\n",
    "        loss.backward() # backpropagate results\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.977\n"
     ]
    }
   ],
   "source": [
    "# How correct were we?\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total +=1\n",
    "            \n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last batch still stored\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot first element of last batch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# prediction for first element of last batch\n",
    "print(torch.argmax(net(X[0].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
